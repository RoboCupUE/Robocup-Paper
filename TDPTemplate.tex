\documentclass[runningheads,a4paper]{llncs}

% XeLaTeX support
\usepackage{ifxetex}
\ifxetex%
	\usepackage{fontspec}
	\usepackage{polyglossia}
	\setmainlanguage{english}
\else
	\usepackage[utf8]{inputenc}
	\usepackage[T1]{fontenc}
	\usepackage[english]{babel}
\fi

% Common packages
\usepackage{amsmath}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{url}
\usepackage{float}
\usepackage{titling}
\usepackage{wrapfig}
\usepackage{booktabs}
\usepackage{csquotes}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{lastpage}
\usepackage[all]{nowidow}
\usepackage[inline]{enumitem}
\usepackage[usenames,dvipsnames]{xcolor}

% Referencing packages
\usepackage{varioref}
\usepackage[hidelinks]{hyperref}
\usepackage[noabbrev,nameinlink]{cleveref}

\usepackage{lipsum}


\input{macros}
\titlerunning{Tech-bROS 2025 Team Description Paper}


\providecommand{\keywords}[1]
{
  \small	
  \textbf{\textit{Keywords---}} #1
}

% Evitar que las secciones actualicen los marcadores de encabezado
\makeatletter
\renewcommand{\sectionmark}[1]{}
\renewcommand{\subsectionmark}[1]{}
\makeatother


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Title
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%novalidate
\pretitle{\centering\large\textbf{RoboCup@Home 2025 OPL}\par}
\title{\Large\textbf{Tech-bROS 2025 Team Description Paper}}

\author{
    Daniel Cuesta Sanz de Madrid\inst{1} \and
    Javier Jesús Chouza Picallo\inst{1} \and
    Pablo Escudero Sarabia\inst{1} \and
    Johnny Leonardo Roca Mendoza\inst{1} \and
    Fernando González Ramos\inst{1}
}

\institute{
    STEAM School, Universidad Europea de Madrid, Spain,\\
    \email{contact@robohome2025.com}\\
    \and
    Robotics Club, Universidad Europea de Madrid, Spain,\\
    \email{clubroboticsuem@gmail.com}
}



\begin{document}


\maketitle
\markboth{Tech-bROS 2025 Team Description Paper}{Tech-bROS 2025 Team Description Paper}
\begin{center}
    \textsuperscript{1}Robotics Club, Universidad Europea de Madrid, Spain\\
    \texttt{clubroboticsuem@gmail.com}
\end{center}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Abstract
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
Tech-Bros (stylized as Tech-bROS), a multidisciplinary team from the Universidad Europea de Madrid, is proud to present its contributions for the RoboCup@Home 2025 submission. Our research focuses on advancing autonomous robotic systems by integrating state-of-the-art technologies in perception, navigation, and human-robot interaction. The team leverages its diverse expertise, combining the knowledge of researchers and students, to address critical challenges in service robotics.
\bigbreak
By participating in RoboCup for the first time, Tech-bROS seeks to showcase these advancements while fostering collaboration and knowledge exchange within the global robotics community. \\
\keywords{Navigation, Service Robotics, Human-robot interaction}

 
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% añadir mas robotitos
\section{Introduction}

Tech-bROS, a team of researchers and (mostly) undergrad students from the Universidad Europea de Madrid, is dedicated to advancing robotics through innovative approaches to service robotics and human-robot interaction. Participating in RoboCup @Home 2025\cite{robocupathomeedu} represents a pivotal step for our team in showcasing our work in dynamic and competitive environments. With a focus on the Open Platform League (OPL), we aim to explore the limits of current robotic capabilities while contributing to the global robotics community.
\bigbreak
Our research leverages the TurtleBot 4, Turtlebot 3 and Turtlebot 2 as a robust and reliable standard set of platforms to address complex tasks in navigation, perception, and human interaction. By integrating cutting-edge technologies such as real-time localization, adaptive planning and deep learning technologies, we strive to develop solutions that are not only effective but also scalable to real-world applications. Furthermore, our work emphasizes user-centric design principles, ensuring robots can interact naturally and effectively with humans in service environments.

This paper outlines our team’s approach to solving the challenges posed by the OPL. We present an overview of the software and system architecture used to enhance all of our robots' functionality, as well as the methodologies employed in our experiments. Additionally, we discuss our key contributions to advancing autonomous robotics, including the development of adaptable interaction frameworks and robust navigation systems. Through this participation, we aim to demonstrate the practical and scientific relevance of our solutions in the context of RoboCup’s mission to advance the field of robotics.


\section{Background}

Recent studies done at our institution have indicated that user experience (UX) and the physical form of robots are critical factors in determining how users view and interact with robotic systems \cite{corrales2023embodiment}.

Expanding upon this groundwork, our study at Tech-bROS seeks to apply these discoveries to ever-changing service settings, concentrating on immediate adjustability and varied interaction systems. We are inspired by embodiment principles and strive to create a robot that can promote natural and efficient communication through movement, guaranteeing a positive user experience in different situations like household chores and teamwork scenarios. 

Building on this foundation, our research at Tech-bROS aims to extend these findings to dynamic service environments, focusing on real-time adaptability and multi-modal interaction frameworks. Inspired by the principles of embodiment, we aim to develop a robot capable of fostering natural and effective communication, ensuring a positive user experience in various contexts, such as domestic tasks and collaborative settings.

\section{Prior Experience}
Even though our team is new to the family of Robocup competitions, several members of our team have prior experience in other kinds of competitions, for instance, last year at the \textbf{ASTI Robotics Challenge} our team \textit{`Duck Fighters`} won first place overall at best performance and the 'Best Sumo Robot' award.\cite{ASTIRobotics2024} \



\section{Refinement in Path planning and localization systems}
One of the main contributions of our team is taking a shot at the improvement and refinement of navigation systems using the Nav2 stack.

In order to achieve this main goal, we used the widest possible set of robotic systems, in our case the last 3 generations of Turtlebot robots:
\begin{figure}[H]
    \centering
    \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[angle=-90,origin=c,width=\textwidth]{images/ourtb4.jpg}
        \caption{Our Turtlebot 4}
        \label{fig:turtlebot4_1}
    \end{minipage}
    \hfill
    \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[angle=-90,origin=c,width=\textwidth]{images/ourtb3.jpg}
        \caption{Our set of Turtlebot 3 Burger}
        \label{fig:turtlebot4_2}
    \end{minipage}
    \hfill
    \begin{minipage}{0.28\textwidth}
        \centering
        \includegraphics[angle=-90,origin=c,width=\textwidth]{images/ourtb2.jpg}
        \caption{Our Turtlebot 2 Kobuki}
        \label{fig:turtlebot4_3}
    \end{minipage}
\end{figure}

Most of our initial research relied on the oldest platform, the \textit{Kobuki}, since it is the most widely documented platform out of the three. The main intention is to standardize the tools that are used within the Nav2 stack setup process and create a subset of tools and scripts that work straight out of the box so that researchers and hobbyists minimize time spent on non-essential configuration adjustments to ensure smooth functionality. We still are currently in the process of porting some of these tools to the latest generation of Turtlebot robots, however, we have already achieved significant progress in bridging the compatibility gap. This involves creating modular configurations that adapt seamlessly across different hardware and software setups, ensuring that the transition between robotic platforms is both intuitive and efficient.\cite{RoboCupUE}

\section{Waymarking in Social Robotics}
The autonomy of robots has been a primary goal for researchers in recent decades. This research focused on waymarking, the ability for a robot to generate and  update multiple environmental signals that aid navigation for themselves and other robots. The study emphasized on human-robot interaction (HRI), using natural language to ask questions like “Where am I?” or “Where can I go?”, enabling it to gather more detailed environmental information. This data is then used to update or improve navigation signals stored in RFID tags, which can be used by other robots in the future.\cite{corrales2021embodiment}

The system was tested using the social robot Maggie in a real indoor environment. Maggie used RFID tags to navigate and added or updated signals autonomously when data was missing or outdated. The study demonstrated the benefits of HRI in enhancing a robot's understanding of the environment.

\section{Other relevant contributions}

\subsection{Open-Source ROS 2 utilities and package development}
As part of our commitment to fostering collaboration and innovation within the robotics community, Tech-bROS is currently developing a set of open-source utilities and packages tailored for the ROS 2 ecosystem. These tools are designed to enhance the capabilities of standard platforms such as the TurtleBot family of robots while ensuring accessibility and reusability for other research teams.

\begin{itemize}
    \item \textbf{Website:} \url{https://robocupue.github.io/techbrosweb.github.io/}
    \item \textbf{Github:} \url{https://github.com/RoboCupUE}
    \item \textbf{Demo Videos:} \url{https://www.youtube.com/@roboticsuem}
\end{itemize}

All packages are publicly available on GitHub under open-source licenses, ensuring transparency and encouraging their use and improvement by the robotics community.

\subsection{Integration of a Social Robot in a Pedagogical and Logopedic Intervention with Children: A Case Study}
This research explored the integration of the NAO humanoid robot in pedagogical and logopedic interventions for children with specific learning and speech therapy needs. Conducted with five children, the study examined the robot's role as a therapeutic tool in supporting tasks like reading comprehension, phonetics, and articulation. The robot’s adaptive architecture evolved during the study to address the unique and dynamic needs of each child, enhancing engagement and fostering motivation.

The study concluded that robots of the same caliber could effectively supplement therapeutic interventions. However, challenges such as reliance on a programmer and response delays highlighted areas for improvement. Future work will focus on enhancing robot autonomy, refining speech recognition, and equipping therapists to manage sessions independently, making social robots more viable for broader therapeutic applications.\cite{corrales2020embodiment}

\section{Other experiments and results}

\subsection{Mapping, Localization and Navigation}
As part of our efforts to refine the robot's navigation capabilities, we conducted a comprehensive mapping of the second floor of our faculty building. This process involved generating an accurate 2D map using LiDAR and camera sensors and the \textit{Slam\_Toolbox} ROS2 package, ensuring that all structural and environmental features were captured effectively. During the mapping process, several adjustments were made to improve the fidelity of the generated map, such as correcting alignment errors and fine-tuning sensor parameters.
\begin{figure}[H]
    \centering
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/mapping.png}
        \caption{\textit{Kobuki} mapping in-progress}
        \label{fig:mapping}
    \end{minipage}
    \hfill
    \begin{minipage}{0.4\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/uem_floor1_clean.png}
        \caption{Generated map file}
        \label{fig:uem_floor1_clean}
    \end{minipage}
\end{figure}

Once the map was finalized, we used then AMCL (\textit{Adaptative Monte-Carlo Localization}) localization algorithms to ensure that the robot could determine its position with high precision while navigating through the environment. Using the Nav2 stack, we successfully enabled the robot to perform pathfinding tasks through various predefined locations in the map.

To optimize its movement, we established a series of waypoints that defined a fixed route for the robot. This setup allowed the robot to follow a structured path while dynamically avoiding obstacles such as people and furniture. Using real-time sensor data, the robot was able to adapt to changes in its environment, ensuring smooth navigation and efficient path execution. This demonstrated the reliability of our system in handling dynamic scenarios, further validating the robustness of our approach.
\begin{figure}[H]
    \centering
    \begin{minipage}{0.30\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/uem_floor1_waypoint.png}
        \caption{Waypoint locations}
        \label{fig:waypoints}
    \end{minipage}
    \hfill
    \begin{minipage}{0.6\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/a_to_b.png}
        \caption{Following specified route}
        \label{fig:a_to_b}
    \end{minipage}
\end{figure}

These waypoints can then be adjusted in real-time, and along with other technologies such as the one described in the next point, can be used for object localization and interacting with moving objects.



\subsection{Semantic 3D Mapping from Deep Image Segmentation}
One of our members participated in a study detailing the 3D mapping of Deep Image segmented views \cite{Martín2021Semantic}. This paper details the deployment of a system that allows for a standard LIDAR point cloud to be semantically enriched using deep learning-based image segmentation. The approach solves the boundary pixel problem, a common issue where inaccuracies occur in aligning segmented pixels from 2D images to their corresponding 3D points in the point cloud.

The proposed algorithm uses a novel mapping strategy that accurately projects segmented pixels onto the point cloud, ensuring better alignment and reliability. This was validated using real-world data from a RGBD camera, where the system demonstrated significant improvements over baseline methods in terms of accuracy and computational efficiency.

Furthermore, the study applied this algorithm to create a semantic 3D map of an indoor environment for a mobile robot, enabling better navigation and environmental understanding. Such advancements showcase the potential of integrating deep learning with robotic mapping systems to enhance autonomous navigation in complex environments.

\section{Conclusions and Future Work}

Tech-bROS has made significant strides in advancing autonomous robotics within the realm of ROS2, focusing on navigation, perception, and human-robot interaction. Our work with the TurtleBot platforms, the Nav2 Stack, SLAM and many other tools has demonstrated the importance of creating scalable, plug-and-play solutions for diverse applications. Additionally, our contributions to social robotics and therapeutic interventions highlight the potential of robots in dynamic and human-centered environments.

Looking forward, our future efforts will focus on:
\begin{itemize}
    \item Enhancing real-time decision-making and adaptability in dynamic scenarios.
    \item Refining human-robot interaction, particularly in natural language understanding through the use of facial expression detection.
    \item Expanding our open-source ROS tools for broader platform compatibility.
    \item Leveraging RoboCup participation to validate and showcase our advancements.
\end{itemize}

By addressing these areas, Tech-bROS aims to continue pushing the boundaries of service robotics while fostering collaboration within the global robotics community.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Bibliography
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{unsrt}
\bibliography{bibliography}



\clearpage{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Robot Specifications
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\robospecs{}

\input{RobotDescriptionOPL}


\nocite{*}

\end{document}
